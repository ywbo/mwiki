
> #### 8、有几百万消息持续积压了几小时，说说怎么解决？ 

【场景假设】现在消费端出故障了，然后大量消息在 MQ 中堆积，现在出事故了，慌得一批。

几千万的数据在 MQ 中积压了，从下午4点多到晚上9点多，这是我们之前真是遇到过的一个场景，确实是线上出故障了，这个时候要不然就是修复 `consumer` 的问题，让它恢复消息速度，然后傻傻等待几个小时，等消息消费完毕，但是这样效率太低下了，而且还傻等着，浪费时间。这在面试的时候肯定不能说吧。

一个消费者 1 秒是 1000 条，1 秒 3个消费者是 3000 条，1 分钟就是 18 万条。所以如果积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。

一般这个时候，只能紧急扩容了，那具体我们应该怎么做呢？具体的思路和步骤如下：

- 先修复 `consumer` 的问题，确保其恢复消费速度，然后将现有的所有 `consumer` 全部都停掉。
- 新建一个 `topic`，`partition` 是原来的 `10` 倍，临时建立好原先 `10` 倍的 `Queue` 数量。
- 写一个临时的分发数据的 `consumer` 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时处理**，直接均匀轮询写入临时建立好的 `10` 倍数量的 `Queue`。
- 如果有条件，临时征用 `10` 倍的机器来部署 `consumer`，每一批 `consumer` 消费一个临时 `Queue` 的数据。这种做法相当于是临时将 `Queue` 资源和 `consumer` 资源扩大 `10` 倍，以正常的速度来消费。
- 等快读消费完积压的数据之后，得**恢复原先部署的架构**，**重新**用原来的 `consumer` 机器来消费消息。
