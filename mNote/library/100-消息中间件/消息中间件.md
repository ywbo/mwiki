## 消息中间件

> #### 0、平时有使用过那些消息中间件？它们有什么区别？ 

平时工作中使用过`RabbitMQ`，`Kafka`。

| 特性                    | RabbitMQ                                           | Kafka                                                        |
| ----------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 单机吞吐量              | 万级，比Kafka低一个等级                            | 10万级，高吞吐，一般配合大数据类的系统来进行实时数据计算，体质采集等场景。 |
| topic数量对吞吐量的影响 | —                                                  | topic从几十到几百个时，吞吐量会大幅下降，在同等机器下，Kafka尽量保证topic数量不要过多，如果出现要支撑大规模的topic，需要增加更多的机器资源。 |
| 时效性                  | 微秒级，这是RabbitMQ一大特点，延时最低。           | 延迟在ms以内                                                 |
| 可用性                  | 高可用，基于主从架构实现高可用                     | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用。 |
| 消息可靠性              | 基本不会丢失消息                                   | 经过参数优化，可以做到0丢失                                  |
| 功能支持                | 基于Erlang开发，并发能力很强，性能极好，延时很低。 | 功能较为简单，主要支持简单的MQ功能，在大数据领域实时计算以及日志采集被大规模使用。 |

> #### 1、为什么使用消息队列？消息队列有什么优点，缺点？ 

	  要根据自己业务需求，实际使用场景出发，选择最为合适的就好。不管使用的是何种类型的MQ，业务场景有很多，集中起来比较核心就是3个：**`解耦`**、**`异步`**、**`削峰`**。下面来逐个说明：

1. > ###### **解耦**

   有这么一个场景。A系统发送数据到B、C、D三个系统，通过接口调用发送。如果E系统也要这个数据呢？那如果C系统现在不需要这个数据了呢？A系统负责人估计头皮发麻，都要崩溃了......

   ![1661861729417](D:\OpenCode\1661861729417.png)

   	  在这个场景中，A系统跟其他七七八八的系统严重耦合。A系统产生了一条关键的数据，很多系统都需要A系统将这个数据发送过来。A系统要时时刻刻考虑B、C、D、E四个系统挂了改怎么办？要不要重新发送数据？要不要把消息存起来？A最直接的结果就是头发花白，最终猝死。:skull:
	
   	  那么换个角度，如果使用MQ，A系统产生一条数据，发送到MQ中，哪个系统需要数据自己去MQ里面去消费。如果新系统需要数据，直接从MQ里消费即可。如果某个系统不需要这条数据了，就取消对MQ消息的消费即可。这样下来，A系统压根儿需要去考虑给谁发送消息，不需要维护这个那个七七八八的代码，也不需要考虑人家是否调用成功，失败或者超时的情况。

   ![1661863532050](D:\OpenCode\1661863532050.png)

   **`【总结】通过对于消息MQ队列的使用，Pub/Sub发布订阅消息这么一个模型，A系统就跟其他系统实现了彻底解耦。`**

2. > ###### **异步**

   	  再来看一个场景，A系统接收一个请求，需要在自己本地写库，还需要在B、C、D三个系统写库，自己本地写库需要3ms，B、C、D三个系统写库分别需要200ms，300ms，100ms。最终请求总时间是：3+200+300+100 = 603ms，如果数据量再大一些，只会比这个时间更长，这就导致，用户感觉搞个东西，怎么响应这个慢。

   ![1661862453165](D:\OpenCode\1661862453165.png)

   	  一般互联网类的企业，对于用户操作响应在200ms以内，对于用户而言几乎是无感的。

   如果**`使用MQ`**，那么A系统连续发送3条消息到MQ队列中，加入耗时5ms，A系统从接受一个请求到返回响应给用户，总时长是 3+5=8ms，对于用户而言，就是点击个页面是事儿，相比于之前没有使用MQ的场景，简直不要太爽啊！

   ![1661863063542](D:\OpenCode\1661863063542.png)

3. > ###### **`削峰`**

   	  每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。
	
   	  一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

   但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

   ![1661864303442](D:\OpenCode\1661864303442.png)

> #### 2、如何保证消息队列的高可用？

	  如果面试问到MQ，高可用是必问的，问题1中已经说明了MQ会导致**`系统可用性降低`**，以及它的缺点，没有人会拿着有点再来聊吧，那么问题自然而然就是要解决MQ的缺点带来的问题。那么接下来还是使用过的RabbitMQ和Kafka来分别聊聊它们的`高可用性是如何保证`的？

1. > ##### RabbitMQ的高可用性

   	  RabbitMQ是比较典型的代表，因为它的高可用是基于主从（非分布式）。我们就以RabbitMQ为例子，讲解第一种`非分布式类型的MQ的高可用性`是怎么实现的？

   这里我们需要先闭上眼睛问问自己一个问题：`RabbitMQ有哪几种部署模式呢？`

   RabbitMQ有三种部署模式：`单机模式`，`普通集群模式`，`镜像集群模式`。

   - ###### 单机模式

     即单机情况不做集群，Demo级别的，就单独运行一个 RabbitMQ 而已，一般就是本地启动玩玩儿，没人生产用单机模式。

   - ###### 普通集群模式（无高可用性）

     普通集群模式，默认模式，即就是在多台机器上启动多个 RabbitMQ 实例，每台机器启动一个。你`创建的 queue，只会放在一个 RabbitMQ 实例上`，但是每个实例都同步 queue 的元数据（元数据可以理解为 queue 的一些配置信息，通过元数据，可以找到 queue 所在的实例）。当消费者过来消费时，实际上如果连接到另外一个实力上，那么被连接的实例会从 queue 所在实例上拉取消息过来。

     ![1661914800167](D:\OpenCode\1661914800167.png)

     	  实际上这种方式确实很麻烦，实际上也不怎么好，`没有作到分布式，就是个普通的集群`。因为这导致要么消费者每次随机连接一个实例 pull 数据，要么固定连接一个 queue 所在实例进行消费数据，前者`有数据 pull 的开销`，后者导致`单实例性能瓶颈`。
	
     	  假设这么一种场景，上图中放置实际数据的 queue1 所在的机器宕机了，会导致其他实例就无法从这个实例中拉取数据，如果此时 queue1 `开启了消息持久化`，让 RabbitMQ 落地存储消息的话，`消息不一定会丢`，那就得等 queue1 这个实例恢复了，然后再继续从这个 queue1 中 pull 数据。
	
     	  所以这个事儿就很尴尬，这就`没有所谓的高可用性而言，这个方案主要是为了提高吞吐量的`，就是说让集群中多个节点来服务某个 queue 的读写操作。

   - ###### 镜像集群模式（高可用性）

     	这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通模式一样的是，在镜像集群模式下，你创建的 Queue，无论是元数据还是 Queue 里的实际消息都会存在于多个实例上，这也就是说，每个 RabbitMQ 节点都是有这个 Queue 的一个完整的镜像，这个完整镜像的含义即 Queue 的全部数据。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

     ![1661916583360](D:\OpenCode\1661916583360.png)

     	  那么如何开启这个`镜像集群模式`呢？其实还比较简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是`镜像集群模式的策略`，指定的时候可以要求数据同步到所有的节点上，也可以要求同步到指定数量的节点，再次创建 Queue 时，应用这个策略，会自动将数据同步到其策略对应的机器上。

     	  我们知道，凡事都有两面性，这样的处理方式有好也有坏。好处在于，集群中任何一个集群宕机了，问题不大，其他机器的（节点）包含了这个 Queue 的完整数据，别的 Consumer 都可以到其他节点上继续消费数据。坏处在于，第一，这个性能的开销也太大了吧？？消息需要同步到所有的机器（节点）上，这就导致网络带宽的压力非常之大，消耗也很重。第二，要是这么玩儿的话，不采取分布式，就没有拓展性而言了。如果某个 Queue 的负载很重，只是一味地加机器，新增的机器也会包含这个 Queue 的所有数据，本质上没有办法线性拓展当前的 Queue。试想，如果这个 Queue 的数据量很大，大到这个机器上的容量无法容纳了，此时怎么办呢？

2. > ##### Kafka的高可用性

   	  这里我们先来简单聊聊Kafka最基本的 架构认知：Kafka 开源之初到0.8版本，采用的是 Scala 语言开发的客户端，存在着诸多设计缺陷。就比如，0.8 版本之前是没有 HA 机制的，即任何一个 broker 宕机了，那么 broker 上的 partition 就废了，没办法读，更没有什么高可用性而言了。从0.9.x版本开始，Kafka 主要采用 Java 语言开发客户端，也修复了之前的设计缺陷。
	
   	  Kafka 由多个 `broker（节点）` 组成，每个 broker 是一个节点；当生产者创建一个 `topic（主题）`，这个 topic 可以划分为多个 `partition（分区）`，每个 partition 可以存在于不同的 broker 之上，`每个 partition 就存放一部分数据`。

   WHAT？？这不就是`天然的分布式消息队列`嘛！！即就是`一个 topic 的数据，是分散存放在多个机器上的，每个机器只存放部分数据`。

   	  有如下场景，假设生产者创建了一个 topic，指定其 partition 数量是3个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 1/3 的数据丢失，因此这种做法也是不能够达到高可用目的。

   ![1662016105419](D:\OpenCode\1662016105419.png)

   	  Kafka 0.9.x版本开始，提供了 HA 机制，就是 `replica（复制品）副本机制`。每个 partition 的数据都会同步到其他机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 `leader 副本`出来，那么生产者和消费者都跟这个 leader 打交道，然后`其他的 replica 就是 follower 副本`。写的时候，leader 会负责吧所有数据同步到 follower 上，读的时候，就直接读取 leader 上的数据即可。那么不禁要问，只能读写？？很简单，要是你可以随意读写每个 follower，那么叫 care 数据的一致性问题，系统复杂度太高，很容易出问题的。`Kafka 会均匀的将每个 partition 的所有 replica 分布在不同的机器上`，这样才可以提高容错性。

   ![1662017805231](D:\OpenCode\1662017805231.png)

   	  这么一搞，就有`高可用性`的那味儿了。因为如果某个时刻某个 broker 宕机了，没关系啊，别忘了宕机的 broker 上的 partition 在其他机器上有 replica 副本的啊。如果这个宕机的 broker 上面有某个 partition的 leader，那么此时会从 follower 中`重新选举一个新的 leader` 出来，大家继续读写新的 leader 即可。这就是所谓的高可用性。
	
   	  `写数据时，生产者就写 leader，然后 leader 将数据落地到本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦多有的 follower 同步好数据，就会发送 ack 给 leader，leader 收到所有的 follower 的 ack 之后，就会返回写消息成功给生产者。`（当然，这只是 Kafka 消息发送的模式之一，还可以适当的调整这个行为。这里不再赘述。）
	
   	  `消费时，只会从 leader 去读，但是只有当一个消息被所有的 follower 都同步成功，并且返回 ack 时，这个消息才会被消费者读到。`
	
   	  聊到这里，我想你应该明白了 Kafka 是如何保证自己的高可用机制了叭，对嘛？如果面试中条件允许，你可以当面画画图，这不就就高手吹牛的基本方式嘛。:laughing: 至于涉及到深层次的内容，这个打铁还需自身硬啊，没事儿多研究研究。如果不面架构师，以上这些内容作为回答我想应该质量还是挺可以的。

> #### 3、如何保证消息不被重复消费？（或者说如何保证消息消费的幂等性？） 

	  拿到问题先不要慌，咽口口水压压惊。:smile_cat: 首先可以聊聊大概`有哪些场景会导致重复消费的问题`。
	
	  首先，比如众多MQ中，

> #### 4、如何保证消息的可靠性传输？（或者说如何处理消息丢失的问题？） 



> #### 5、如何保证消息的顺序性？ 



> #### 6、如何解决消息队列的延时以及过期失效问题？ 



> #### 7、消息队列满了以后该怎么处理？ 



> #### 8、有几百万消息持续积压了几小时，说说怎么解决？ 



> #### 9、如果让你来设计一个消息队列中间件，该如何进行架构设计？说说你的思路。

