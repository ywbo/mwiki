## 消息中间件

#### 0、平时有使用过那些消息中间件？它们有什么区别？ 

平时工作中使用过`RabbitMQ`，`Kafka`。

| 特性                    | RabbitMQ                                           | Kafka                                                        |
| ----------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 单机吞吐量              | 万级，比Kafka低一个等级                            | 10万级，高吞吐，一般配合大数据类的系统来进行实时数据计算，体质采集等场景。 |
| topic数量对吞吐量的影响 | —（RabbitMQ中无topic概念一说）                     | topic从几十到几百个时，吞吐量会大幅下降，在同等机器下，Kafka尽量保证topic数量不要过多，如果出现要支撑大规模的topic，需要增加更多的机器资源。 |
| 时效性                  | 微秒级，这是RabbitMQ一大特点，延时最低。           | 延迟在ms以内                                                 |
| 可用性                  | 高可用，基于主从架构实现高可用                     | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用。 |
| 消息可靠性              | 基本不会丢失消息                                   | 经过参数优化，可以做到0丢失                                  |
| 功能支持                | 基于Erlang开发，并发能力很强，性能极好，延时很低。 | 功能较为简单，主要支持简单的MQ功能，在大数据领域实时计算以及日志采集被大规模使用。 |

#### 1、为什么使用消息队列？消息队列有什么优点，缺点？ 

要根据自己业务需求，实际使用场景出发，选择最为合适的就好。不管使用的是何种类型的MQ，业务场景有很多，集中起来比较核心就是3个：**`解耦`**、**`异步`**、**`削峰`**。下面来逐个说明：

1. > ###### **解耦**

   有这么一个场景。A系统发送数据到B、C、D三个系统，通过接口调用发送。如果E系统也要这个数据呢？那如果C系统现在不需要这个数据了呢？A系统负责人估计头皮发麻，都要崩溃了......

   ![image-20220903203507884](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903203507884.png)

   在这个场景中，A系统跟其他七七八八的系统严重耦合。A系统产生了一条关键的数据，很多系统都需要A系统将这个数据发送过来。A系统要时时刻刻考虑B、C、D、E四个系统挂了改怎么办？要不要重新发送数据？要不要把消息存起来？A最直接的结果就是头发花白，最终猝死。:skull:

   那么换个角度，如果使用MQ，A系统产生一条数据，发送到MQ中，哪个系统需要数据自己去MQ里面去消费。如果新系统需要数据，直接从MQ里消费即可。如果某个系统不需要这条数据了，就取消对MQ消息的消费即可。这样下来，A系统压根儿需要去考虑给谁发送消息，不需要维护这个那个七七八八的代码，也不需要考虑人家是否调用成功，失败或者超时的情况。

   ![image-20220903203606194](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903203606194.png)

   **`【总结】通过对于消息MQ队列的使用，Pub/Sub发布订阅消息这么一个模型，A系统就跟其他系统实现了彻底解耦。`**

2. > ###### **异步**

   再来看一个场景，A系统接收一个请求，需要在自己本地写库，还需要在B、C、D三个系统写库，自己本地写库需要3ms，B、C、D三个系统写库分别需要200ms，300ms，100ms。最终请求总时间是：3+200+300+100 = 603ms，如果数据量再大一些，只会比这个时间更长，这就导致，用户感觉搞个东西，怎么响应这个慢。

   ![image-20220903203642136](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903203642136.png)

   一般互联网类的企业，对于用户操作响应在200ms以内，对于用户而言几乎是无感的。

   如果**`使用MQ`**，那么A系统连续发送3条消息到MQ队列中，加入耗时5ms，A系统从接受一个请求到返回响应给用户，总时长是 3+5=8ms，对于用户而言，就是点击个页面是事儿，相比于之前没有使用MQ的场景，简直不要太爽啊！

   ![image-20220830232823820](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220830232823820.png)

3. > ###### **`削峰`**

   每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。

   一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

   但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

   ![image-20220830232909789](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220830232909789.png)

   如果请求，每秒5k个请求写入MQ，A系统每秒最多能处理2k个请求，因为MySQL每秒钟最多处理2k个请求。A系统从MQ拉取请求，每秒就拉取2k个请求，不要超过自己每秒能处理的最大请求数量就ok，这样下来，哪怕是高分期的时候，A系统也绝对不可能会挂掉，而MQ每秒5k个请求进来，就2k个出去，结果就导致在高峰期（午/晚间1小时），可能有几十万甚至几百万的请求积压在MQ中。

   ![image-20220830235245122](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220830235245122.png)

   这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。

   > #### 1、为什么使用消息队列？消息队列有什么优点，缺点？ 

要根据自己业务需求，实际使用场景出发，选择最为合适的就好。不管使用的是何种类型的MQ，业务场景有很多，集中起来比较核心就是3个：**`解耦`**、**`异步`**、**`削峰`**。下面来逐个说明：

1. > ###### **解耦**

   有这么一个场景。A系统发送数据到B、C、D三个系统，通过接口调用发送。如果E系统也要这个数据呢？那如果C系统现在不需要这个数据了呢？A系统负责人估计头皮发麻，都要崩溃了......

   ![image-20220903201218363](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903201218363.png)

   在这个场景中，A系统跟其他七七八八的系统严重耦合。A系统产生了一条关键的数据，很多系统都需要A系统将这个数据发送过来。A系统要时时刻刻考虑B、C、D、E四个系统挂了改怎么办？要不要重新发送数据？要不要把消息存起来？A最直接的结果就是头发花白，最终猝死。:skull:

   那么换个角度，如果使用MQ，A系统产生一条数据，发送到MQ中，哪个系统需要数据自己去MQ里面去消费。如果新系统需要数据，直接从MQ里消费即可。如果某个系统不需要这条数据了，就取消对MQ消息的消费即可。这样下来，A系统压根儿需要去考虑给谁发送消息，不需要维护这个那个七七八八的代码，也不需要考虑人家是否调用成功，失败或者超时的情况。

   ![image-20220903201515342](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903201515342.png)

   **`【总结】通过对于消息MQ队列的使用，Pub/Sub发布订阅消息这么一个模型，A系统就跟其他系统实现了彻底解耦。`**

2. > ###### **异步**

   再来看一个场景，A系统接收一个请求，需要在自己本地写库，还需要在B、C、D三个系统写库，自己本地写库需要3ms，B、C、D三个系统写库分别需要200ms，300ms，100ms。最终请求总时间是：3+200+300+100 = 603ms，如果数据量再大一些，只会比这个时间更长，这就导致，用户感觉搞个东西，怎么响应这个慢。

   ![image-20220903202013883](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202013883.png)

   一般互联网类的企业，对于用户操作响应在200ms以内，对于用户而言几乎是无感的。

   如果**`使用MQ`**，那么A系统连续发送3条消息到MQ队列中，加入耗时5ms，A系统从接受一个请求到返回响应给用户，总时长是 3+5=8ms，对于用户而言，就是点击个页面是事儿，相比于之前没有使用MQ的场景，简直不要太爽啊！

   ![image-20220903201613600](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903201613600.png)

3. > ###### **`削峰`**

   每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。

   一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

   但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

   ![image-20220903202126536](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202126536.png)
   
   如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。
   
   ![image-20220903202523132](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202523132.png)

#### 2、如何保证消息队列的高可用？

如果面试问到MQ，高可用是必问的，问题1中已经说明了MQ会导致**`系统可用性降低`**，以及它的缺点，没有人会拿着有点再来聊吧，那么问题自然而然就是要解决MQ的缺点带来的问题。那么接下来还是使用过的RabbitMQ和Kafka来分别聊聊它们的`高可用性是如何保证`的？

1. > ##### RabbitMQ的高可用性

   RabbitMQ是比较典型的代表，因为它的高可用是基于主从（非分布式）。我们就以RabbitMQ为例子，讲解第一种`非分布式类型的MQ的高可用性`是怎么实现的？

   这里我们需要先闭上眼睛问问自己一个问题：`RabbitMQ有哪几种部署模式呢？`

   RabbitMQ有三种部署模式：`单机模式`，`普通集群模式`，`镜像集群模式`。

   - ###### 单机模式

     即单机情况不做集群，Demo级别的，就单独运行一个 RabbitMQ 而已，一般就是本地启动玩玩儿，没人生产用单机模式。

   - ###### 普通集群模式（无高可用性）

     普通集群模式，默认模式，即就是在多台机器上启动多个 RabbitMQ 实例，每台机器启动一个。你`创建的 queue，只会放在一个 RabbitMQ 实例上`，但是每个实例都同步 queue 的元数据（元数据可以理解为 queue 的一些配置信息，通过元数据，可以找到 queue 所在的实例）。当消费者过来消费时，实际上如果连接到另外一个实力上，那么被连接的实例会从 queue 所在实例上拉取消息过来。

     ![image-20220903202616343](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202616343.png)

     实际上这种方式确实很麻烦，实际上也不怎么好，`没有作到分布式，就是个普通的集群`。因为这导致要么消费者每次随机连接一个实例 pull 数据，要么固定连接一个 queue 所在实例进行消费数据，前者`有数据 pull 的开销`，后者导致`单实例性能瓶颈`。

     假设这么一种场景，上图中放置实际数据的 queue1 所在的机器宕机了，会导致其他实例就无法从这个实例中拉取数据，如果此时 queue1 `开启了消息持久化`，让 RabbitMQ 落地存储消息的话，`消息不一定会丢`，那就得等 queue1 这个实例恢复了，然后再继续从这个 queue1 中 pull 数据。

     所以这个事儿就很尴尬，这就`没有所谓的高可用性而言，这个方案主要是为了提高吞吐量的`，就是说让集群中多个节点来服务某个 queue 的读写操作。

   - ###### 镜像集群模式（高可用性）

      这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通模式一样的是，在镜像集群模式下，你创建的 Queue，无论是元数据还是 Queue 里的实际消息都会存在于多个实例上，这也就是说，每个 RabbitMQ 节点都是有这个 Queue 的一个完整的镜像，这个完整镜像的含义即 Queue 的全部数据。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

     ![image-20220903202655038](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202655038.png)

     那么如何开启这个`镜像集群模式`呢？其实还比较简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是`镜像集群模式的策略`，指定的时候可以要求数据同步到所有的节点上，也可以要求同步到指定数量的节点，再次创建 Queue 时，应用这个策略，会自动将数据同步到其策略对应的机器上。

     我们知道，凡事都有两面性，这样的处理方式有好也有坏。好处在于，集群中任何一个集群宕机了，问题不大，其他机器的（节点）包含了这个 Queue 的完整数据，别的 Consumer 都可以到其他节点上继续消费数据。坏处在于，第一，这个性能的开销也太大了吧？？消息需要同步到所有的机器（节点）上，这就导致网络带宽的压力非常之大，消耗也很重。第二，要是这么玩儿的话，不采取分布式，就没有拓展性而言了。如果某个 Queue 的负载很重，只是一味地加机器，新增的机器也会包含这个 Queue 的所有数据，本质上没有办法线性拓展当前的 Queue。试想，如果这个 Queue 的数据量很大，大到这个机器上的容量无法容纳了，此时怎么办呢？

2. > ##### Kafka的高可用性

   这里我们先来简单聊聊Kafka最基本的 架构认知：Kafka 开源之初到0.8版本，采用的是 Scala 语言开发的客户端，存在着诸多设计缺陷。就比如，0.8 版本之前是没有 HA 机制的，即任何一个 broker 宕机了，那么 broker 上的 partition 就废了，没办法读，更没有什么高可用性而言了。从0.9.x版本开始，Kafka 主要采用 Java 语言开发客户端，也修复了之前的设计缺陷。

   Kafka 由多个 `broker（节点）` 组成，每个 broker 是一个节点；当生产者创建一个 `topic（主题）`，这个 topic 可以划分为多个 `partition（分区）`，每个 partition 可以存在于不同的 broker 之上，`每个 partition 就存放一部分数据`。

   WHAT？？这不就是`天然的分布式消息队列`嘛！！即就是`一个 topic 的数据，是分散存放在多个机器上的，每个机器只存放部分数据`。

   有如下场景，假设生产者创建了一个 topic，指定其 partition 数量是3个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 1/3 的数据丢失，因此这种做法也是不能够达到高可用目的。

   ![image-20220903202751928](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202751928.png)

   Kafka 0.9.x版本开始，提供了 HA 机制，就是 `replica（复制品）副本机制`。每个 partition 的数据都会同步到其他机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 `leader 副本`出来，那么生产者和消费者都跟这个 leader 打交道，然后`其他的 replica 就是 follower 副本`。写的时候，leader 会负责吧所有数据同步到 follower 上，读的时候，就直接读取 leader 上的数据即可。那么不禁要问，只能读写？？很简单，要是你可以随意读写每个 follower，那么叫 care 数据的一致性问题，系统复杂度太高，很容易出问题的。`Kafka 会均匀的将每个 partition 的所有 replica 分布在不同的机器上`，这样才可以提高容错性。

   ![image-20220903202816257](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220903202816257.png)

   这么一搞，就有`高可用性`的那味儿了。因为如果某个时刻某个 broker 宕机了，没关系啊，别忘了宕机的 broker 上的 partition 在其他机器上有 replica 副本的啊。如果这个宕机的 broker 上面有某个 partition的 leader，那么此时会从 follower 中`重新选举一个新的 leader` 出来，大家继续读写新的 leader 即可。这就是所谓的高可用性。

   `写数据时，生产者就写 leader，然后 leader 将数据落地到本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦多有的 follower 同步好数据，就会发送 ack 给 leader，leader 收到所有的 follower 的 ack 之后，就会返回写消息成功给生产者。`（当然，这只是 Kafka 消息发送的模式之一，还可以适当的调整这个行为。这里不再赘述。）

   `消费时，只会从 leader 去读，但是只有当一个消息被所有的 follower 都同步成功，并且返回 ack 时，这个消息才会被消费者读到。`

   聊到这里，我想你应该明白了 Kafka 是如何保证自己的高可用机制了叭，对嘛？如果面试中条件允许，你可以当面画画图，这不就就高手吹牛的基本方式嘛。:laughing: 至于涉及到深层次的内容，这个打铁还需自身硬啊，没事儿多研究研究。如果不面架构师，以上这些内容作为回答我想应该质量还是挺可以的。

#### 3、如何保证消息不被重复消费？（或者说如何保证消息消费的幂等性？） 

拿到问题先不要慌，咽口口水压压惊。:smile_cat: 首先可以聊聊大概`有哪些场景会导致重复消费的问题`。

  首先，比如众多MQ（RabbitMQ，ActiveMQ，Kafka）中，都有可能会出现重复消费的问题，这是很正常的。正常？为什么？因为这个问题通常不是由MQ保证的，是由我们研发同学来保证的。下面我们就来说说Kafka中是如何 重复消费的？

Kafka实际上有一个 `offset` 的概念，即就是每个消息写进去。都有一个offset，代表着消息的序号，然后 `consumer`消费了消息之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示说：“我已经消费过了，下次要是重启啥的，你就让我从上次消费的 offset 来继续消费吧。”

凡事都有个意外，没有意外的话，意外就要发生了。比如我们之前生产经常遇到的问题，就是当你有时候重启系统，但是这个重启也要看怎么重启了？如果碰到着急点儿的，或者是新手，直接把进程 `kill` 掉，再重启，这会导致一个很严重的问题，消费者 `consumer` 有些消息处理了，但是还没有来得及提交 `offset`，哦豁~ 尴了个噶~ 重启之后，有些消息就会重复消费一次。

:chestnut: 举个栗子

有这么一个场景。数据1/2/3依次进入 Kafka，Kafka会给这个三条数据每条分配一个 offset，代表着这条数据的序号，我们就假设分配的 `offset 依次是 101/102/103`。消费者从 Kafka 去消费的时候，也会按照这个顺序取消费。假如当消费者消费了 `offset = 101` 这条消息，刚准备提交 `offset` 到 `Zookeeper`，此时消费者进程被重启了。那么此时消费过的数据 `1/2` 的 offset 并没有提交了，Kafka 也就不知道你已经消费了 `offset = 100` 的这条消息数据。那么重启后，消费找 Kafka 说，嘿~ 哥们儿，刚我重启了，你告诉我上次消息消费到哪个地儿了，把那个地方后面的数据继续给我传过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致`重复消费`。

【注意】新版的 Kafka 已经将 `offset` 的存储从 `Zookeeper` 转移至 `Kafka brokers`，并使用内部位移主题 `_consumer_offsets` 进行存储。

![image-20220904224346742](%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6.assets/image-20220904224346742.png)
如果消费者干的事儿是拿一条数据就往数据库写一条，会导致说，你可能把数据 1/2 在数据库插入了2次，那么数据就错啦。其实重复消费的问题不可怕，可怕的是你没考虑到重复消费之后，`怎么保证幂等性`。

:chestnut: 举个栗子

假如你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复消费了两次，你不就插入了两条数据，不符合我们的预期，这数据不就错了吗？但是你要消费到第二次的时候，自己判断一下是否已经消费过了，如若已经消费过了，就直接丢弃，这样不就只保留了一条数据，从而保证了数据的正确性。

`一条数据重复出现两次，数据库里就只有一条是数据，这就保证了系统的幂等性。`

`那何谓幂等性，通俗来讲，就是一条数据，或者一个请求，给你重复来了多次，你得确保对应的数据是不会改变的，不能出错。`

那么此时第二个问题来了，怎么保证消息队列的消费的幂等性？

这里可不能张口就来，最好是结合业务来思考，这里可以尝试从以下几个角度聊聊：

- 比如你哪个数据要写库，你先根据数据的主键查一把，如果这条数据有了，那你就别插入了，`update` 一下可以的吧。

- 比如你要写入的是 Redis，那更好了，每次都是 `SET`，天然的幂等性。
- 比如你不是上面两个场景，那座的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加上全局唯一的标识（id），类似于订单id之类的东西，这里可以捎着讲讲`分布式ID生成策略`（雪花算法，百度UidGenerator，美团的Leaf），然后你这里消费到了之后，现根据这个id，比如去Redis或者数据库查一下之前有没有消费过吗？如果没有，你就处理，然后这个 id 写入 Redis 或者数据库。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入就会报错，不会导致数据库中出现脏数据。

![1662452858848](D:\OpenCode\1662452858848.png)

【总结】当然，如何保证MQ的消息是幂等性的，在实际应用中需要结合具体的业务来分析。

#### 4、如何保证消息的可靠性传输？（或者说如何处理消息丢失的问题？） 
上一个问题我们聊到了数据一条也不能多（重复消费）的问题，那么现在我们来聊聊数据一条也不能少（消息丢失）的问题。我们还是从熟知的 `RabbitMQ` 和 `Kafka` 分别来分析说明吧。

- **RabbitMQ**

  - **生产者弄丢了数据**

    生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路搞丢了，因为网络的问题啥的，都有可能。

    此时成功选择用 `RabbitMQ 提供的事务`功能，就是`生产者发送数据前`开启 RabbitMQ 事务 `channel.txSelect()`，然后发送消息，如果消息没有成功的被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 `channel.txRollback()`，然后重试发送消息；如果收到了消息，那么就可以提交事务 `channel.txCommit()`。

    ```java
    try{
                // 通过工厂创建连接
                connection = factory.newConnection();
                // 获取信道
                channel = connection.createChannel();
                // 开启事务
                channel.txSelect();
                // 发送消息
                channel.basicPublish(exchange, routingKey, MessageProperties.PRESISTENT_TEXT_PLAIN, msg.getBasic());
                // 模拟出现异常
                int result = 1 / 0;
                // 提交事务
                channel.txCommit();
            } catch (IOException | TimeoutException e){
                // 捕获异常，回滚事务
                channe.txRollback();
            }
    ```

    但是问题是，RabbitMQ 事务机制（同步）一搞，基本上`吞吐量就会下来，因为太耗性能`。

    所以一般来说，如果你确保写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，如果写入 RabbitMQ 中，那么 RabbitMQ 会回传给你一个 `ack` 消息，告诉你说这个消息OK了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接受失败，你可以重试。当然你可以结合这个机制，自己在内存里维护每个消息 id 的状态，如果超过一定时间，还没有接收到这个消息的回调，那么你可以重发。

    事务机制和 `confirm` 机制最大的不同在于，`事务机制是同步的`，你提交一个事务之后会阻塞在那儿，但是 `confirm 机制是异步的` ，你发送一条消息之后就可以接着发送下一条消息，那个消息 RabbitMQ 接收到了之后会异步调用你的一个接口通知你这个消息接收到了。

    所以一般在生产者这块避免丢失数据，都是采用 `confirm` 机制的。

    > 【注意】已经在 `transaction` 事务模式的 `channel` 是不能在设置成 `confirm` 模式的，即这两种模式是**不能共存**的。

    客户端实现 `confirm` 有3中方式：

  - a. **普通 `confirm` 模式**：每发送一条消息后，调用 `waitForConfirms()` 方法，等待服务器端 `confirm`，如果服务端返回 `false` 或者在一段时间内都没有返回，客户端可以进行消息重发。

    ```java
    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());
    if (!channel.waitForConfirms()) {
        // 消息发送失败
        // ...
    }
    ```

  - b. **批量 `confirm` 模式**：每发送一批消息后，调用 调用 `waitForConfirms()` 方法，等待服务器端 `confirm`。

    ```java
    channel.confirmSelect();
    for (int i = 0; i < batchCount; ++i) {
        channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());
    }
    if (!channel.waitForConfirms()) {
        // 消息发送失败
        // ...
    }
    ```

  - c. **异步 `confirm` 模式**：提供一个回调方法，服务端 `confirm` 了一条或者多条消息后客户端会回调这个方法。

    ```java
    SortedSet<Long> confirmSet = Collections.synchronizedSortedSet(new TreeSet<Long>());
    channel.confirmSelect();
    channel.addConfirmListener(new ConfirmListener() {
        public void handleAck(long deliveryTag, boolean multiple) throws IOException {
            if (multiple) {
                confirmSet.headSet(deliveryTag + 1).clear();
            } else {
                confirmSet.remove(deliveryTag);
            }
        }
    
        public void handleNack(long deliveryTag, boolean multiple) throws IOException {
            System.out.println("Nack, SeqNo: " + deliveryTag + ", multiple: " + multiple);
            if (multiple) {
                confirmSet.headSet(deliveryTag + 1).clear();
            } else {
                confirmSet.remove(deliveryTag);
            }
        }
    });
    
    while (true) {
        long nextSeqNo = channel.getNextPublishSeqNo();
        channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());
        confirmSet.add(nextSeqNo);
    }
    ```

  - **RabbitMQ 弄丢了消息**

    就是消息从生产者到 RabbitMQ 后，RabbitMQ 自己把数据搞丢了，这个`必须要开启 RabbitMQ 的持久化`，就是消息写入之后，会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，`恢复之后就会自动读取之前存储的数据`，这也是 RabbitMQ 最重要的特征之一，一般不会丢。除非极为罕见的场景，比如 RabbitMQ 还没有持久化，自己就挂了，可能导致少量的数据丢失，但是这个概率是很小的。

    这里讲到的持久化，那么怎么配置持久化呢？有`两个步骤`：

    - a. `创建 Queue 的时候，将其设置为持久化`。这样就保证 RabbitMQ 持久化 Queue 的`元数据`，但是它是`不会持久化 Queue 里面的数据`的。

    - b. 发送消息的时候，将 `消息的 deliveryMode` 设置为 `2`。这样就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去，结果不巧，此时 RabbitMQ 挂了，就会导致内存里面的一点点数据丢失。

      所以，持久化跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以重新发送的。

  - **消费者弄丢了数据**

    RabbitMQ 如果丢失了数据，主要是因为你消费的时候，`刚消费到，还没有处理，结果进程就挂了`。比如重启了，那么久尴了个尬，RabbitMQ 认为你都消费了，这数据不就嗝儿拜了嘛。想象一下这种场景该怎么处理呢？

    上面我们说到了 RabbitMQ 提供的 `ack` 机制，这里就要派上大用场了。简单来说，就是你`关闭 RabbitMQ 的自动的 ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没有处理完，不就没有 `ack` 了？？那 RabbitMQ 就认为还没处理完，这个时候，RabbitMQ 会把这个消费给别的 `consumer` 去处理，消息是不会丢失的。

    > 为了保证消息从队列中可靠的到达消费者，RabbitMQ 提供了消息确认机制。消费者在声明队列是时，可以指定 `noAck` 参数，当 `noAck = false`，RabbitMQ 会等待消息显示发回 `ack` 信号后，才从内存（如磁盘，如果是持久化消息）中移除消息。否则一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它。

![1662466754050](D:\OpenCode\1662466754050.png)

- > #### **Kafka**

- **生产者会不会弄丢数据？**

  我们前边就说过，Kafka 有 replica 副本机制。那么要求 `producer` 端设置成 `ack = all`，这样就要求每条数据，必须写入所有的 `replica` 之后，才能认为是写成功了。当 `leader` 接收到消息，所有的 `follower` 都同步到消息之后，才认为本次写成功了，如果满足这个条件，生产者会自动不断的重试，重试无限次。所以是一定不会丢数据的。

- **Kafka 弄丢了消息**

  这块比较常碰到的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。我们试想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，结果选举某个 follower 成 leader 之后，不就少一些数据吗？这就是丢失数据呀！

  这样的场景，在生产环境也遇到过。之前的 Kafka 的 leader 宕机了，将 follower 切换为 leader 之后，就会发现一些数据丢失了。

  所以基于此，我们一般要求起码设置如下 `4` 个参数：

  - 给 `topic` 设置 `replication.factor` 参数：这个参数值必须大于 1，要求每个 partition 必须有至少 2 个副本。
  - 在 Kafka 服务端设置 `min.insycn.replicas` 参数：这个参数值必须大于 1，要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了，还有一个 follower 吧。
  - 在 `producer` 端设置 `ack = all` ：要求每一条数据，必须`写入所有的 replica 之后，才能认为是写成功了`。
  - 在 `producer` 端设置 `retries = MAX`（很大很大很大的一个值，意思是无限重试）：要求一旦`写入失败，就无限重试`，卡在这里了。

  这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在的 broker 发生故障，进行 leader 切换是，数据不会丢失。

- **消费者弄丢了数据**

  唯一能够导致消费者弄丢数据的情况，就是你消费到了这个消息，然后消费者那边自己自动提交了 offset，让 Kafka 以为你已经消费好了这个消息，但实际上你才刚准备处理这个消息，你还没有处理，结果自己挂了，此时，这条消息就丢失了。

  > 【号外】在 Kafka 中`默认`的消费位移（offset）的提交方式是`自动提交`。这个由消费者客户端参数 `enable.auto.commit` 配置，默认值为 `true`。当然这个默认的的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数 `auto.commit.interval.ms` 配置，默认值为 5 秒，此参数生效前提是 `enable.auto.commit` 配置值为 `true`。

  那这不就和 RabbitMQ 差不多了吗？我们都知道，`Kafka 会自动提交 offset` ，那有没有配置可以关闭自动提交这种方式呢？答案是肯定的，Kafka 提供了客户端参数 `enable.auto.commit`，默认值为 `true`（自动提交），我们需将其配置值修改为 `false`（关闭自动提交），在处理完后自己手动提交 `offset` 就可以保证数据不会丢失。那么数据丢失的问题解决了，此时确实还是`有可能会有消息重复消费`，比如你刚出完数据，还没来得及提交 `offset`，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性（参考问题3：如何保证消息消费的幂等性）就好了。

  生产环境遇到这样的场景，就是我们的 Kafka 消费者消费到了数据之后，是先写到内存的 Queue 中先缓存一下，结果有时你刚把消息写入内存 Queue，然后消费者自动提交了 offset。此时我们重启了系统，就会导致内存的 Queue 里还没有来得及处理的数据就丢失了。

> #### 5、如何保证消息的顺序性？ 

其实这问题就是可以拆解为两个角度分析。① 你了解顺序这个事儿吗？② 你有没有办法保证消息是有顺序的？

老规矩，我们还是先来看看 RabbitMQ 和 Kafka 顺序会错乱的俩场景：

- #### **RabbitMQ**

  - 场景

    一个 Queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条消息，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别中 MQ 中消费者三条数据中的一条，结果 消费者2 先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱套了吗？如图：

    ![1662533327060](D:\OpenCode\1662533327060.png)
    
    
  - **解决方案**

    拆分成多个 `Queue`，每个 Queue 一个 Consumer，就是多一些 Queue 而已，确实是麻烦点儿，这样也会造成吞吐量的下降，可以在消费者内部采用多线程的方式去消费。

    或者就是一个 Queue 对应一个 consumer，然后这个 consumer 内部`用内存队列做排序`，然后分发给底层不同的 `worker` 来处理。

    > 【注意】这里消费者不直接消费消息，而是将消息根据关键值（比如：订单 id）进行哈希，哈希值相同的消息保存到相同的内存队列里。也就是说，需要保证顺序的消息存到了相同的内存队列中，而后由一个唯一的 `worker` 去处理。

  ![1662534354653](D:\OpenCode\1662534354653.png)

- #### **Kafka**

  - 场景

    假如我们创建了一个 `topic`，它有三个 `partition`。生产者在写的时候，其实可以指定一个 `key`，比如我们指定了某个订单的 id 作为 key，那么这个订单相关的数据一定会被分配到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。
    

#### 5、如何保证消息的顺序性？ 

#### 6、如何解决消息队列的延时以及过期失效问题？ 

#### 7、消息队列满了以后该怎么处理？ 

#### 8、有几百万消息持续积压了几小时，说说怎么解决？ 

#### 9、如果让你来设计一个消息队列中间件，该如何进行架构设计？说说你的思路。
