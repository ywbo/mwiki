> ## 2、如何保证消息队列的高可用？ 
>

如果面试问到MQ，高可用是必问的，问题1中已经说明了MQ会导致**`系统可用性降低`**，以及它的缺点，没有人会拿着有点再来聊吧，那么问题自然而然就是要解决MQ的缺点带来的问题。那么接下来还是使用过的RabbitMQ和Kafka来分别聊聊它们的`高可用性是如何保证`的？

1. > ##### RabbitMQ的高可用性

   RabbitMQ是比较典型的代表，因为它的高可用是基于主从（非分布式）。我们就以RabbitMQ为例子，讲解第一种`非分布式类型的MQ的高可用性`是怎么实现的？

   这里我们需要先闭上眼睛问问自己一个问题：`RabbitMQ有哪几种部署模式呢？`

   RabbitMQ有三种部署模式：`单机模式`，`普通集群模式`，`镜像集群模式`。

   - ###### 单机模式

     即单机情况不做集群，Demo级别的，就单独运行一个 RabbitMQ 而已，一般就是本地启动玩玩儿，没人生产用单机模式。

   - ###### 普通集群模式（无高可用性）

     普通集群模式，默认模式，即就是在多台机器上启动多个 RabbitMQ 实例，每台机器启动一个。你`创建的 queue，只会放在一个 RabbitMQ 实例上`，但是每个实例都同步 queue 的元数据（元数据可以理解为 queue 的一些配置信息，通过元数据，可以找到 queue 所在的实例）。当消费者过来消费时，实际上如果连接到另外一个实力上，那么被连接的实例会从 queue 所在实例上拉取消息过来。

     ![image-20220903202616343](03-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F.assets/image-20220903202616343.png)

     实际上这种方式确实很麻烦，实际上也不怎么好，`没有作到分布式，就是个普通的集群`。因为这导致要么消费者每次随机连接一个实例 pull 数据，要么固定连接一个 queue 所在实例进行消费数据，前者`有数据 pull 的开销`，后者导致`单实例性能瓶颈`。

     假设这么一种场景，上图中放置实际数据的 queue1 所在的机器宕机了，会导致其他实例就无法从这个实例中拉取数据，如果此时 queue1 `开启了消息持久化`，让 RabbitMQ 落地存储消息的话，`消息不一定会丢`，那就得等 queue1 这个实例恢复了，然后再继续从这个 queue1 中 pull 数据。

     所以这个事儿就很尴尬，这就`没有所谓的高可用性而言，这个方案主要是为了提高吞吐量的`，就是说让集群中多个节点来服务某个 queue 的读写操作。

   - ###### 镜像集群模式（高可用性）

      这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通模式一样的是，在镜像集群模式下，你创建的 Queue，无论是元数据还是 Queue 里的实际消息都会存在于多个实例上，这也就是说，每个 RabbitMQ 节点都是有这个 Queue 的一个完整的镜像，这个完整镜像的含义即 Queue 的全部数据。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

     ![image-20220903202655038](03-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F.assets/image-20220903202655038.png)

     那么如何开启这个`镜像集群模式`呢？其实还比较简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是`镜像集群模式的策略`，指定的时候可以要求数据同步到所有的节点上，也可以要求同步到指定数量的节点，再次创建 Queue 时，应用这个策略，会自动将数据同步到其策略对应的机器上。

     我们知道，凡事都有两面性，这样的处理方式有好也有坏。好处在于，集群中任何一个集群宕机了，问题不大，其他机器的（节点）包含了这个 Queue 的完整数据，别的 Consumer 都可以到其他节点上继续消费数据。坏处在于，第一，这个性能的开销也太大了吧？？消息需要同步到所有的机器（节点）上，这就导致网络带宽的压力非常之大，消耗也很重。第二，要是这么玩儿的话，不采取分布式，就没有拓展性而言了。如果某个 Queue 的负载很重，只是一味地加机器，新增的机器也会包含这个 Queue 的所有数据，本质上没有办法线性拓展当前的 Queue。试想，如果这个 Queue 的数据量很大，大到这个机器上的容量无法容纳了，此时怎么办呢？

2. > ##### Kafka的高可用性

   这里我们先来简单聊聊Kafka最基本的 架构认知：Kafka 开源之初到0.8版本，采用的是 Scala 语言开发的客户端，存在着诸多设计缺陷。就比如，0.8 版本之前是没有 HA 机制的，即任何一个 broker 宕机了，那么 broker 上的 partition 就废了，没办法读，更没有什么高可用性而言了。从0.9.x版本开始，Kafka 主要采用 Java 语言开发客户端，也修复了之前的设计缺陷。

   Kafka 由多个 `broker（节点）` 组成，每个 broker 是一个节点；当生产者创建一个 `topic（主题）`，这个 topic 可以划分为多个 `partition（分区）`，每个 partition 可以存在于不同的 broker 之上，`每个 partition 就存放一部分数据`。

   WHAT？？这不就是`天然的分布式消息队列`嘛！！即就是`一个 topic 的数据，是分散存放在多个机器上的，每个机器只存放部分数据`。

   有如下场景，假设生产者创建了一个 topic，指定其 partition 数量是3个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 1/3 的数据丢失，因此这种做法也是不能够达到高可用目的。

   ![image-20220903202751928](03-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F.assets/image-20220903202751928.png)

   Kafka 0.9.x版本开始，提供了 HA 机制，就是 `replica（复制品）副本机制`。每个 partition 的数据都会同步到其他机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 `leader 副本`出来，那么生产者和消费者都跟这个 leader 打交道，然后`其他的 replica 就是 follower 副本`。写的时候，leader 会负责吧所有数据同步到 follower 上，读的时候，就直接读取 leader 上的数据即可。那么不禁要问，只能读写？？很简单，要是你可以随意读写每个 follower，那么叫 care 数据的一致性问题，系统复杂度太高，很容易出问题的。`Kafka 会均匀的将每个 partition 的所有 replica 分布在不同的机器上`，这样才可以提高容错性。

   ![image-20220903202816257](03-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F.assets/image-20220903202816257.png)

   这么一搞，就有`高可用性`的那味儿了。因为如果某个时刻某个 broker 宕机了，没关系啊，别忘了宕机的 broker 上的 partition 在其他机器上有 replica 副本的啊。如果这个宕机的 broker 上面有某个 partition的 leader，那么此时会从 follower 中`重新选举一个新的 leader` 出来，大家继续读写新的 leader 即可。这就是所谓的高可用性。

   `写数据时，生产者就写 leader，然后 leader 将数据落地到本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦多有的 follower 同步好数据，就会发送 ack 给 leader，leader 收到所有的 follower 的 ack 之后，就会返回写消息成功给生产者。`（当然，这只是 Kafka 消息发送的模式之一，还可以适当的调整这个行为。这里不再赘述。）

   `消费时，只会从 leader 去读，但是只有当一个消息被所有的 follower 都同步成功，并且返回 ack 时，这个消息才会被消费者读到。`

   聊到这里，我想你应该明白了 Kafka 是如何保证自己的高可用机制了叭，对嘛？如果面试中条件允许，你可以当面画画图，这不就就高手吹牛的基本方式嘛。:laughing: 至于涉及到深层次的内容，这个打铁还需自身硬啊，没事儿多研究研究。如果不面架构师，以上这些内容作为回答我想应该质量还是挺可以的。