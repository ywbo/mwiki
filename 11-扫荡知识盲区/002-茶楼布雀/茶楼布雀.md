# 茶楼布雀

## 1. ConcurrentHashMap所有知识

- **ConcurrentHashMap的实现原理**
  - **ConcurrentHashMap1.7和1.8的区别？**
  - **ConcurrentHashMap使用什么技术来保证线程安全**
- **ConcurrentHashMap的put()方法**
  - **ConcurrentHashmap 不支持 key 或者 value 为 null 的原因？**
  - **put()方法如何实现线程安全呢？**
- **ConcurrentHashMap扩容机制**
- **ConcurrentHashMap的get方法是否要加锁，为什么？**
- **其他问题**
  - **为什么使用ConcurrentHashMap**
  - **ConcurrentHashMap迭代器是强一致性还是弱一致性？HashMap呢？**
  - **JDK1.7与JDK1.8中ConcurrentHashMap的区别**

### (1) ConcurrentHashMap的`实现原理`

ConcurrentHashMap的出现主要为了解决hashmap在并发环境下不安全，JDK1.8ConcurrentHashMap的设计与实现非常精巧，大量的利用了volatile，CAS等乐观锁技术来减少锁竞争对于性能的影响，**ConcurrentHashMap保证线程安全的方案是：**

- **JDK1.8：synchronized+CAS+HashEntry+红黑树；**
- **JDK1.7：ReentrantLock+Segment+HashEntry。**

#### ① JDK7 ConcurrentHashMap

在JDK1.7中ConcurrentHashMap由Segment(分段锁)数组结构和HashEntry数组组成，且主要通过Segment(分段锁)段技术实现线程安全。

Segment是一种可重入锁，是一种数组和链表的结构，一个Segment中包含一个HashEntry数组，每个HashEntry又是一个链表结构，因此在ConcurrentHashMap查询一个元素的过程需要进行两次Hash操作，如下所示：

- 第一次Hash定位到Segment；
- 第二次Hash定位到元素所在的链表的头部；

![img](https://segmentfault.com/img/remote/1460000024432654)

正是通过Segment分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。

这样结构会使Hash的过程要比普通的HashMap要长，影响性能，但写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，ConcurrentHashMap提升了并发能力。

#### ② JDK8 ConcurrentHashMap

在JDK8ConcurrentHashMap内部机构：数组+链表+红黑树，Java 8在链表长度超过一定阈值(8)时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N)))，结构基本上与功能和JDK8的HashMap一样，只不过ConcurrentHashMap保证线程安全性。

![img](https://segmentfault.com/img/remote/1460000024432653)

但在JDK1.8中摒弃了Segment分段锁的数据结构，基于CAS操作保证数据的获取以及使用synchronized关键字对相应数据段加锁来实现线程安全，这进一步提高了并发性。

```java
static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val;  // 使用了 volatile 属性
        volatile Node<K,V> next; // 使用了 volatile 属性

        Node(int hash, K key, V val, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.val = val;
            this.next = next;
        }

        public final K getKey()       { return key; }
        public final V getValue()     { return val; }
        public final int hashCode()   { return key.hashCode() ^ val.hashCode(); }
        public final String toString(){ return key + "=" + val; }
        public final V setValue(V value) {
            throw new UnsupportedOperationException();
        }

        public final boolean equals(Object o) {
            Object k, v, u; Map.Entry<?,?> e;
            return ((o instanceof Map.Entry) &&
                    (k = (e = (Map.Entry<?,?>)o).getKey()) != null &&
                    (v = e.getValue()) != null &&
                    (k == key || k.equals(key)) &&
                    (v == (u = val) || v.equals(u)));
        }

        /**
         * Virtualized support for map.get(); overridden in subclasses.
         */
        Node<K,V> find(int h, Object k) {
            Node<K,V> e = this;
            if (k != null) {
                do {
                    K ek;
                    if (e.hash == h &&
                        ((ek = e.key) == k || (ek != null && k.equals(ek))))
                        return e;
                } while ((e = e.next) != null);
            }
            return null;
        }
    }
```

ConcurrentHashMap采用Node类作为基本的存储单元，每个键值对(key-value)都存储在一个Node中，使用了volatile关键字修饰value和next，保证并发的可见性。其中Node子类有：

- ForwardingNode：扩容节点，只是在扩容阶段使用的节点，主要作为一个标记，在处理并发时起着关键作用，有了ForwardingNodes，也是ConcurrentHashMap有了分段的特性，提高了并发效率
- TreeBin：TreeNode的代理节点，用于维护TreeNodes，ConcurrentHashMap的红黑树存放的是TreeBin
- TreeNode：用于树结构中，红黑树的节点（当链表长度大于8时转化为红黑树），此节点不能直接放入桶内，只能是作为红黑树的节点
- ReservationNode：保留结点

ConcurrentHashMap中查找元素、替换元素和赋值元素都是基于`sun.misc.Unsafe`中**原子操作**实现**多并发的无锁化**操作。

```java
/* ---------------- Table element access ------- */
/* ---------------- 表元素访问 -------------- */

static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}

static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,                      Node<K,V> c, Node<K,V> v) {
    return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}

static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
    U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
}
```

### (2) ConcurrentHashMap的put()方法

ConcurrentHashMap 的 `put` 流程步骤：

##### a. 如果key或者value为null，则抛出空指针异常，和HashMap不同的是HashMap单线程是允许为Null；

```java
if (key == null || value == null) throw new NullPointerException();
```

##### b. for的死循环，为了实现CAS的无锁化更新，如果table为null或者table的长度为0，则初始化table，调用`initTable()`方法（第一次put数据，调用默认参数实现，其中重要的`sizeCtl`参数）。

```java
//计算索引的第一步，传入键值的hash值
    int hash = spread(key.hashCode());
    int binCount = 0; //保存当前节点的长度
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh; K fk; V fv;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable(); //初始化Hash表
        ...
    }
```

##### c. 确定元素在Hash表的索引

通过hash算法可以将元素分散到哈希桶中。在ConcurrentHashMap中通过如下方法确定数组索引：

		第一步：

```java
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS; 
}
```

		第二步：`(length-1) & (h ^ (h >>> 16)) & HASH_BITS);`

##### d. 通过`tableAt()`方法找到位置`tab[i]`的`Node`,当Node为null时为没有`hash`冲突的话，使用`casTabAt()`方法`CAS`操作将元素插入到`Hash`表中，`ConcurrentHashmap`使用`CAS`无锁化操作，这样在高并发`hash`冲突低的情况下，性能良好。

```java
else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
    //利用CAS操作将元素插入到Hash表中
    if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
        break;  // no lock when adding to empty bin(插入null的节点，无需加锁)
}
```

##### e. 当f不为null时，说明发生了hash冲突，当f.hash == MOVED==-1 时，说明`ConcurrentHashmap`正在发生`resize`操作,使用`helpTransfer()`方法帮助正在进行resize操作。

```java
else if ((fh = f.hash) == MOVED) //f.hash == -1 
    //hash为-1 说明是一个forwarding nodes节点，表明正在扩容
    tab = helpTransfer(tab, f);
```

##### f. 以上情况都不满足的时，使用`synchronized`同步块上锁当前节点`Node `,并判断有没有线程对数组进行了修改，如果没有则进行：

- 遍历该链表并统计该链表长度`binCount`，查找是否有和key相同的节点，如果有则将查找到节点的val值替换为新的value值，并返回旧的value值，否则根据key，value，hash创建新Node并将其放在链表的尾部
- 如果`Node f`是`TreeBin`的类型，则使用红黑树的方式进行插入。然后则退出`synchronized(f)`锁住的代码块

```java
//当前节点加锁
synchronized (f) {
    //判断下有没有线程对数组进行了修改
    if (tabAt(tab, i) == f) {
        //如果hash值是大于等于0的说明是链表
        if (fh >= 0) {
            binCount = 1;
            for (Node<K,V> e = f;; ++binCount) {
                K ek;
                //插入的元素键值的hash值有节点中元素的hash值相同，替换当前元素的值
                if (e.hash == hash &&
                    ((ek = e.key) == key ||
                     (ek != null && key.equals(ek)))) {
                    oldVal = e.val;
                    if (!onlyIfAbsent)
                        //替换当前元素的值
                        e.val = value;
                    break;
                }
                Node<K,V> pred = e;
                //如果循环到链表结尾还没发现，那么进行插入操作
                if ((e = e.next) == null) {
                    pred.next = new Node<K,V>(hash, key, value);
                    break;
                }
            }
        }else if (f instanceof TreeBin) { //节点为树
            Node<K,V> p;
            binCount = 2;
            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                  value)) != null) {
                oldVal = p.val;
                if (!onlyIfAbsent)
                    //替换旧值
                    p.val = value;
            }
        }
        else if (f instanceof ReservationNode)
            throw new IllegalStateException("Recursive update");
    }
}
```

##### g. 执行完`synchronized(f)`同步代码块之后会先检查`binCount`,如果大于等于TREEIFY_THRESHOLD = 8则进行treeifyBin操作尝试将该链表转换为红黑树。

```java
if (binCount != 0) {
    //如果节点长度大于8,转化为树
    if (binCount >= TREEIFY_THRESHOLD)
        treeifyBin(tab, i);
    if (oldVal != null)
        return oldVal; 
    break;
}
```

##### h. 执行了一个`addCount`方法,主要用于统计数量以及决定是否需要扩容.

```java
addCount(1L, binCount);
```



#### ① ConcurrentHashmap 不支持 key 或者 value 为 null 的原因？

`ConcurrentHashmap`和`hashMap`不同的是，`concurrentHashMap`的`key`和`value`都不允许为null，因为`concurrenthashmap`它们是用于多线程的，并发的 ，如果`map.get(key)`得到了null，不能判断到底是映射的value是null,还是因为没有找到对应的key而为空，就有了`二义性`。而用于单线程状态的`hashmap`却可以用`containKey（key）` 去判断到底是否包含了这个null。

#### ② put()方法如何实现线程安全呢？

##### a. 在第一次put数据时，调用`initTable()`方法

```java
 /**  
 * Hash表的初始化和调整大小的控制标志。为负数，Hash表正在初始化或者扩容;  
 * (-1表示正在初始化,-N表示有N-1个线程在进行扩容)  
 * 否则，当表为null时，保存创建时使用的初始化大小或者默认0;  
 * 初始化以后保存下一个调整大小的尺寸。  
 */  
 private transient volatile int sizeCtl;  
     //第一次put，初始化数组  
     private final Node<K,V>[] initTable() {  
         Node<K,V>[] tab; int sc;  
         while ((tab = table) == null || tab.length == 0) {  
             //如果已经有别的线程在初始化了，这里等待一下  
             if ((sc = sizeCtl) < 0)  
             Thread.yield(); // lost initialization race; just spin  
             //-1 表示正在初始化  
             else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {  
             ...  
         } finally {  
            sizeCtl = sc;  
         }  
            break;  
         }  
     }  
     return tab;  
 }
```

##### b. 使用`sizeCtl`参数作为控制标志的作用，当在从插入元素时，才会初始化Hash表。在开始初始化的时候，

- 首先判断`sizeCtl`的值，如果**sizeCtl < 0**，说明**有线程在初始化**，**当前线程便放弃初始化操作**。否则，将**SIZECTL设置为-1**，**Hash表进行初始化**。
- 初始化成功以后，将`sizeCtl`的值设置为当前的容量值

##### i. 在不存在hash冲突的时

```java
else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {  
     //利用CAS操作将元素插入到Hash表中  
     if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))  
     break;  // no lock when adding to empty bin(插入null的节点，无需加锁)  
 }
```

`(f = tabAt(tab, i = (n - 1) & hash)) == null`中使用tabAt原子操作获取数组，并利用`casTabAt(tab, i, null, new Node<K,V>(hash, key, value))`CAS操作将元素插入到Hash表中。

##### ii. 在存在hash冲突时，先把当前节点使用关键字`synchronized`加锁，然后再使用`tabAt()`原子操作判断下有没有线程对数组进行了修改，最后再进行其他操作。

### ③ 为什么要锁住更新操作的代码块？

因为发生了哈希冲突，当前线程正在f所在的链表上进行更新操作，假如此时另外一个线程也需要到这个链表上进行更新操作，则需要等待当前线程更新完后再执行。

```java
//当前节点加锁  
synchronized (f) {  
     //这里判断下有没有线程对数组进行了修改  
     if (tabAt(tab, i) == f) {  
     ......//do something  
 }
}
```

### (3) ConcurrentHashMap扩容机制

##### ① 扩容变量

```java
// 新 tab 的 length  
int nextn = nextTab.length;  
// 创建一个 fwd 节点，用于占位。当别的线程发现这个槽位中是 fwd 类型的节点，则跳过这个节点。  
ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);  
// 首次推进为 true，如果等于 true，说明需要再次推进一个下标（i--）  
//反之，如果是 false，那么就不能推进下标，需要将当前的下标处理完毕才能继续推进  
boolean advance = true;  
// 完成状态，如果是 true，就结束此方法。  
boolean finishing = false; // to ensure sweep before committing nextTab
```

##### ② 因为`ConcurrentHashMap`支持多线程扩容，多个线程处理不同的节点，首先先计算出每个线程（CPU）处理的桶数：将 length / 8 然后除以 CPU核心数。如果得到的结果小于 16，那么就使用 16。（避免出现转移任务不均匀的现象）

```java
// 新 tab 的 length  
int nextn = nextTab.length;  
// 创建一个 fwd 节点，用于占位。当别的线程发现这个槽位中是 fwd 类型的节点，则跳过这个节点。  
ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);  
// 首次推进为 true，如果等于 true，说明需要再次推进一个下标（i--）  
//反之，如果是 false，那么就不能推进下标，需要将当前的下标处理完毕才能继续推进  
boolean advance = true;  
// 完成状态，如果是 true，就结束此方法。  
boolean finishing = false; // to ensure sweep before committing nextTab
```

##### ③ 新的 table 尚未初始化，进行2倍扩容

```java
 if (nextTab == null) {            // initiating  
     try {  
         // 扩容  2 倍  
         Node<K,V>[] nt = (Node<K,V>\[])new Node<?,?>[n << 1];  
         // 更新  
         nextTab = nt;  
     } catch (Throwable ex) {      // try to cope with OOME  
         // 扩容失败， sizeCtl 使用 int 最大值。  
         sizeCtl = Integer.MAX_VALUE;  
         return;// 结束  
     }  
     // 更新成员变量  
     nextTable = nextTab;  
     // 更新转移下标，就是 老的 tab 的 length  
     transferIndex = n;  
 }
```

##### ④ 在死循环中，每个线程先取得自己需要转移的桶的区间：先获取CAS 修改 transferIndex，即 length - 区间值，留下剩余的区间值供后面的线程使用(i 表示下标，bound 表示当前线程可以处理的当前桶区间最小下标)。

- 判断`--i`是否大于等于`bound` ，正常情况下，如果大于 bound 不成立，说明该线程上次领取的任务已经完成了。那么，需要在下面继续领取任务。
- `transferIndex` 小于等于0，说明没有区间了 ，i 改成 -1，推进状态变成 false，不再推进，表示，扩容结束了，当前线程可以退出了
- 第一次进入循环，走下面的 nextIndex 赋值操作（获取最新的转移下标）。其余情况都是：如果可以推进，将 i 减一，然后修改成不可推进。如果 i 对应的桶处理成功了，改成可以推进。

```java
int nextIndex, nextBound;  
 if (--i >= bound || finishing)  
     //是为了防止在没有成功处理一个桶的情况下却进行了推进   
     advance = false;  
     else if ((nextIndex = transferIndex) <= 0) {  
     i = -1;  
     advance = false;  
 } else if ((nextIndex = transferIndex) <= 0) {
         // 如果小于等于0，说明没有区间了 ，i 改成 -1，
         //推进状态变成 false，不再推进，表示，扩容结束了，当前线程可以退出了
         // 这个 -1 会在下面的 if 块里判断，从而进入完成状态判断
         i = -1;
         advance = false;
 } 
 else if (U.compareAndSwapInt  
     (this, TRANSFERINDEX, nextIndex,  
     nextBound = (nextIndex > stride ?  
     nextIndex - stride : 0))) {  
     //当前线程可以处理的最小当前区间最小下标   
     bound = nextBound;  
     //初次对i 赋值，这个就是当前线程可以处理的当前区间的最大下标  
     i = nextIndex - 1;   
     advance = false;  
 }
```

##### ⑤ 判断该节点是否需要进行扩容处理

- 是否已完成扩容
  - `finishing`为`true`，完成扩容
  - 如果没完成
    - 这个线程结束帮助扩容了`U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)`为true
- `(f = tabAt(tab, i)) == null`,获取老 tab i 下标位置的变量，如果是 null，写入 fwd 占位，推进下个下标
- `(fh = f.hash) == MOVED`说明别的线程已经处理过了，再次推进一个下标。
- 以上情况都不符合就说明，这个位置有实际值了，且不是占位符，需要对这个节点`synchronized`上锁，进行数据迁移

```java
if (i < 0 || i >= n || i + n >= nextn) {
            int sc;
            if (finishing) { // 如果完成了扩容
                nextTable = null;// 删除成员变量
                table = nextTab;// 更新 table
                sizeCtl = (n << 1) - (n >>> 1); // 更新阈值
                return;// 结束方法。
            }// 如果没完成
           // 尝试将 sc -1. 表示这个线程结束帮助扩容了，将 sc 的低 16 位减一。
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                // 如果 sc - 2 等于标识符左移 16 位，说明没有线程在帮助他们扩容了
                if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)。
                    return;// 不相等，说明没结束，当前线程结束方法。
                finishing = advance = true;// 如果相等，扩容结束了，更新 finising 变量
                i = n; // 再次循环检查一下整张表
            }
        }
        // 获取老 tab i 下标位置的变量，如果是 null就写入fwd占位，再次推进一个下标
        else if ((f = tabAt(tab, i)) == null) 
            advance = casTabAt(tab, i, null, fwd);
        // 如果不是 null 且 hash 值是 MOVED,说明别的线程已经处理过了，再次推进一个下标。
        else if ((fh = f.hash) == MOVED)
            advance = true;  
        else {// 到这里，说明这个位置有实际值了，且不是占位符。对这个节点上锁。
            //为什么上锁，防止 putVal 的时候向链表插入数据
            synchronized (f) { 
    ....
}
```

1. 扩容时，对该节点`synchronized`加锁,再进行处理,判断 i 下标处的桶节点是否和 f 相同:

- 如果 f 的 hash 值大于 0 ,是链表结构，根据当前节点和首节点的 `hash &n`值取于结果不同，进行处理：

  - 相等为低位节点处理
  - 不相等为高位节点处理

  ```java
  if (fh >= 0) {
      //获取当前
      int runBit = fh & n;
      // 尾节点，且和头节点的 hash 值取于不相等
      Node<K,V> lastRun = f; 
      // 遍历这个桶
      for (Node<K,V> p = f.next; p != null; p = p.next) {
          // 取于桶中每个节点的 hash 值
          int b = p.hash & n;
          // 如果节点的 hash 值和首节点的 hash 值取于结果不同
          if (b != runBit) {
              // 更新 runBit，用于下面判断 lastRun 该赋值给 ln 还是 hn。
              runBit = b;
              lastRun = p; 
          }
      }
      // 如果最后更新的 runBit 是 0 ，设置低位节点
      if (runBit == 0) {
          ln = lastRun;
          hn = null;
      }
      else {// 如果最后更新的 runBit 是 1， 设置高位节点
          hn = lastRun; 
          ln = null;
      }
      for (Node<K,V> p = f; p != lastRun; p = p.next) {
          int ph = p.hash; K pk = p.key; V pv = p.val;
          // 如果与运算结果是 0，那么就还在低位
          if ((ph & n) == 0) // 如果是0 ，那么创建低位节点
              ln = new Node<K,V>(ph, pk, pv, ln);
          else // 1 则创建高位
              hn = new Node<K,V>(ph, pk, pv, hn);
      }
      // 其实这里类似 hashMap 
      // 设置低位链表放在新链表的 i
      setTabAt(nextTab, i, ln);
      // 设置高位链表，在原有长度上加 n
      setTabAt(nextTab, i + n, hn);
      // 将旧的链表设置成占位符
      setTabAt(tab, i, fwd);
      // 继续向后推进
      advance = true;
  }
  ```



  - TreeBin 的 hash 是 -2，是红黑树结构进行处理

    ```java
    else if (f instanceof TreeBin) {
         TreeBin<K,V> t = (TreeBin<K,V>)f;
         TreeNode<K,V> lo = null, loTail = null;
         TreeNode<K,V> hi = null, hiTail = null;
         int lc = 0, hc = 0;
         // 遍历
         for (Node<K,V> e = t.first; e != null; e = e.next) {
              int h = e.hash;
              TreeNode<K,V> p = new TreeNode<K,V>
                               (h, e.key, e.val, null, null);
              // 和链表相同的判断，与运算 == 0 的放在低位
              if ((h & n) == 0) {
                       if ((p.prev = loTail) == null)
                             lo = p;
                       else
                             loTail.next = p;
                       loTail = p;
                       ++lc;
                 } // 不是 0 的放在高位
                 else {
                       if ((p.prev = hiTail) == null)
                               hi = p;
                       else
                               hiTail.next = p;
                       hiTail = p;
                       ++hc;
                     }
              }
       // 如果树的节点数小于等于 6，那么转成链表，反之，创建一个新的树
        ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                  (hc != 0) ? new TreeBin<K,V>(lo) : t;
        hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                     (lc != 0) ? new TreeBin<K,V>(hi) : t;
        // 低位树
        setTabAt(nextTab, i, ln);
        // 高位数
        setTabAt(nextTab, i + n, hn);
        // 旧的设置成占位符
        setTabAt(tab, i, fwd);
        // 继续向后推进
        advance = true;
    }
    ```

  当`ConcurrentHashMap`中元素的数量达到`cap * loadFactor`时，就需要进行扩容。扩容主要通过`transfer()`方法进行，当有线程进行`put`操作时，如果正在进行扩容，可以通过`helpTransfer()`方法加入扩容。也就是说，ConcurrentHashMap支持多线程扩容，多个线程处理不同的节点，实现方式是，将Map表拆分，让每个线程处理自己的区间。如下图：

  ![img](https://segmentfault.com/img/remote/1460000024439088)

### (4) ConcurrentHashMap的get方法是否要加锁，为什么？

```java
public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        //满足条件直接返回对应的值
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
            if ((eh = e.hash) == h) {
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            //e.hash<0，正在扩容
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            //遍历当前节点
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```

ConcurrentHashMap的get方法就是从Hash表中读取数据，并不会与扩容不冲突，因此该方法也不需要同步锁，这样可提高ConcurrentHashMap 的并发性能。

----

### (5) 其它问题

#### ① 为什么使用 ConcurrentHashMap ？

- HashMap在多线程中进行put方法有可能导致程序死循环，因为多线程可能会导致HashMap形成环形链表，(即链表的一个节点的next节点永不为null，就会产生死循环),会导致CPU的利用率接近100%，因此并发情况下不能使用HashMap。
- HashTable通过使用synchronized保证线程安全，但在线程竞争激烈的情况下效率低下。因为当一个线程访问HashTable的同步方法时，其他线程只能阻塞等待占用线程操作完毕。
- ConcurrentHashMap使用分段锁的思想，对于不同的数据段使用不同的锁，可以支持多个线程同时访问不同的数据段，这样线程之间就不存在锁竞争，从而提高了并发效率。

#### ② ConcurrentHashMap迭代器是强一致性还是弱一致性？HashMap呢？

在迭代时，ConcurrentHashMap使用了不同于传统集合的快速失败迭代器，弱一致迭代器。

在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据，iterator完成后再将头指针替换为新的数据，

这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。

#### ③ JDK1.7与JDK1.8中ConcurrentHashMap的区别？

在迭代时，ConcurrentHashMap使用了不同于传统集合的快速失败迭代器，弱一致迭代器。

在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据，iterator完成后再将头指针替换为新的数据，

这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。

## 2. Redis为什么这么快？

Redis不使用表，它的数据库不会预定义或者强制去要求用户对Redis存储的不同数据进行关联。 数据库的工作模式按存储方式可分为：硬盘数据库和内存数据库。 **Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘I/O 速度的限制，所以速度极快** 。具体体现在：

（1）完全基于内存，数据存在内存中，绝大部分请求是纯粹的内存操作，非常快速，跟传统的磁盘文件数据存储相比，避免了通过磁盘IO读取到内存这部分的开销。

（2）数据结构简单，对数据操作也简单。Redis中的数据结构是专门进行设计的，每种数据结构都有一种或多种数据结构来支持。Redis正是依赖这些灵活的数据结构，来提升读取和写入的性能。

（3）采用单线程，省去了很多上下文切换的时间以及CPU消耗，不存在竞争条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，也不会出现死锁而导致的性能消耗。

（4）使用基于IO多路复用机制的线程模型，可以处理并发的连接。

## 
